<!doctype html>
<html lang="ru">
  <head>
    <meta charset="utf-8"/>
    <title>Inside Lucene</title>

    <link rel="stylesheet" href="reveal.js/css/reveal.css">
	  <link rel="stylesheet" href="reveal.js/css/theme/black.css" id="theme">
	  <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css" id="theme">
    <style>
      .reveal p {
        text-align: left;
      }
      .reveal code {
        background-color: #3f3f3f;
        font-size: 0.9em;
      }
      .reveal ul {
        display: block;
        margin-left: 2em;
      }
      .reveal section img {
        background-color: white;
      }
    </style>
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section data-markdown>
          # Effective search
        </section>

        <section>
          <section data-markdown>
            # Why not SQL?
          </section>
          <section data-markdown>
            * Иногда sql медленный, очень медленный
            * MVCC - многоверсионность
            * ACID - атомарнось, согласованность, изоляция, устойчивость
          </section>
          <section data-markdown>
            ## MVCC

            * Записи физически не удаляются из базы
            * Любой запрос выполняется в транзакции, xid_current (32 bit)
            * Каждая запись имеет 2 дополнительных поля: xmin, xmax
            * xmin - номер транзакции вставившей запись
            * xmax - транзакция удалившая запись
          </section>
          <section data-markdown>
            ## VACUUM

            * Процесс autovacuum проставляет xmin = FREEZE
            * И удаляет мертвые версии записей
            * Это нужно для избежания xid wraparound
            * Также отмечает страницы в visibility map,
              позволяя index only scan
          </section>
          <section data-markdown>
            ## XID WRAPAROUND

            ![xid wraparound](images/xid_wraparound.png)
          </section>
          <section data-markdown>
            ## ACID

            Каждая запись проверяется на "видимость":

            ```c
            /*
            * ((Xmin == my-transaction &&
            *		(Xmax is null
            *		 [|| Xmax != my-transaction)])
            * ||
            *
            * (Xmin is committed &&
            *		(Xmax is null ||
            *			(Xmax != my-transaction &&
            *			 Xmax is not committed)))
            */
            ```
          </section>
          <section data-markdown>
            ## Slow SQL

            ```sql
            SELECT count(1) FROM product
            ```
            ```sql
            SELECT * FROM product OFFSET 10_000_000 LIMIT 10
            ```
            ```sql
            SELECT * FROM product ORDER BY random() LIMIT 10
            ```
            ```sql
            SELECT count(DISTINCT company_id) FROM product
            ```
            </script>
          </section>
          <section data-markdown>
            ## Pagination

            * Ограничиваем глубину пагинации
            * Определяем только наличие следующей страницы

            ```sql
            SELECT count(1) FROM
              (SELECT id FROM product LIMIT 11) p
            ```
          </section>
          <section data-markdown>
            ## Process'em all

            * Обрабатываем бакетами
            * Фильтрация и сортировка по одному полю

            ```sql
            SELECT * FROM product
              WHERE id > 10_000_000
              ORDER BY id
              LIMIT 1000
            ```
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Full Text Index

            * Сложность поиска терма - O(1)
            * Wildcard запросы
            * Поиск по фразе
            * Минимальный размер

            <!--
                Размер индекса очень важен, так как улучшает использование дискового кеша.
                Процессоры реально быстрые - раскодировать данные в памяти может оказаться бестрее, чем скопировать их.
                Для упрощения примем, что наш индекс должен быть неизменяемым
                (иммутабельность позволяет активно использовать кеширование).
              -->
          </section>
        </section>
        <section>
          <section data-markdown>
            ## Inverted Index
            ```python
            docs = [
                {"id": "doc1", "status": 2, "name": "the brown fox"},
                {"id": "doc2", "status": 0, "name": "the brown"},
                {"id": "doc3", "name": "the the"},
            ]
            index["name"] = {
                "brown": ["doc1", "doc2"],
                "fox": ["doc1"],
                "the": ["doc1", "doc2", "doc3"],
            }
            ```
          </section>
          <section data-markdown>
            ## Document Ordinals

            ```python
            index["name"] = {
                "brown": [0, 1],
                "fox": [0],
                "the": [0, 1, 2],
            }
            ordinals = ["doc1", "doc2", "doc3"]
            ```
          </section>
          <section data-markdown>
            ## Frequency & Positions

            * Ранжирование
            * Поиск по фразе

            ```python
            index["name"] = {
                "brown": ([0, 1], [1, 1], [[1], [1]]),
                "fox": ([0], [1], [[2]]),
                "the": ([0, 1, 2], [1, 1, 2], [[0], [0], [0, 1]])
            }
            ordinals = ["doc1", "doc2", "doc3"]
            ```

            <!--
                Храним частоту и позиции отдельно от doc ordinals
              -->
          </section>
          <section data-markdown>
            ## Uninverted index

            * Сортировка
            * Скрипты
            * Агрегации

            Раньше FieldCache индекс загружался в память

            ```python
            doc_values["status"] = {
                0: 2,
                1: 0,
                2: None,
            }
            ```
          </section>
          <section data-markdown>
            ## Term vectors

            * Inverted index для каждого документа
            * Частота терма, позиции, смещения в тексте
            * Используется для подсветки

            ```python
            vectors["name"] = {
                0: {
                    "brown": (1, [2], [[4, 9]]),
                    "fox": (1, [3], [[10, 13]]),
                    "the": (1, [1], [[0, 3]]),
                },
                1: {
                    "brown": (1, [2], [[4, 9]]),
                    "the": (1, [1], [[0, 3]]),
                },
                2: {
                    "the": (1, [1, 2], [[0, 3], [4, 7]]),
                },
            }
            ```
          </section>
          <section data-markdown>
            ## Stored

            * Оригинальное значение поля
            * Сжимается LZ4 или GZIP блоками по 16Кб
            * Распаковывается весь блок
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Postings List
          </section>
          <section data-markdown>
            ### Delta + VInt

            ```python
            original = [2, 8, 9, 10, 27, 35, 62]  # 7 * 4 = 28 bytes
            packed = [2, 6, 1, 1, 17, 8, 27]  # 7 * 1 = 7 bytes
            ```

            * Variable Integers - старший бит кодирует есть ли продолжение
            * Integer занимает от 1 до 5 байт

            Минусы:

            * Плохо работает с предсказателем переходов
            * Минимальный размер - 1 байт
            * Нельзя раскодировать произвольное значение
          </section>
          <section data-markdown>
            ### Frame of Reference

            * Упаковывем блоки используя Delta-encoding + Bit packing

            ```python
            original = [2, 8, 9, 10, 27, 35, 62]
            packed = (5, [2, 6, 1, 1, 17, 8, 27])
	    # 1 + 5bit * 7 = 6 bytes
            ```

            * Фиксированный размер
            * Единственное большое значение увеличивает размер
          </section>
          <section data-markdown>
            ### Patched Frame of Reference

            ```python
            original = [2, 8, 9, 10, 27, 35, 62]
            packed = (3, [2, 6, 1, 1]), (5, [17, 8, 27])
            # (1 + 3bit * 4) + (1 + 5bit * 3) = 6 bytes
            ```

            * Блок состоит из 256 значений
            * Большие значения влияют только на один блок
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Filter Cache

            * Должны ускорять выполнение часто используемых фильтров
            * Ключ - это пара (filter, segment)
            * Степень сжатия не так важна - скорость важнее

            <!--
                Я здесь написал "должны", так как не обязательно они будут ускорять.
                Важно кешировать действительно часто используемые фильтры, иначе
                записи в кеше будут постоянно вытеснять друг друга.
                Записи привязаны к сегментам, благодаря иммутабельности последних,
                запись в кеше всегда актуальна.
                Хоть сжатие не так важно как для индекса, но все же чем меньше будет
                занимать запись в кеше, тем больше записей мы можем хранить. Нужен компромис.n
              -->
          </section>
          <section data-markdown>
            ### Sorted Integer

            * Самый простой способ
            * 1 миллион документов занимает 4Мб
            * Нужно что-то более эфективное по памяти
          </section>
          <section data-markdown>
            ### Bitmaps

            * Лучший способ для "плотных" фильтров
            * 1 миллион документов занимает 125Кб
            * Неэфективен для сильно разреженых фильтров
          </section>
          <section data-markdown>
            ### Roaring Bitmaps

            * Взял лучшее из обоих способов
            * Разбивает на блоки по 16 старшим битам
            * Внутри блока сохраняет только 16 младших бит
            * Если в блоке меньше 4096 значений использует массив, иначе bitmap
          </section>
          <section data-markdown>
            ### Roaring Bitmaps

            1. Разбиваем на пары: (N / 16, N % 16)
            2. Группируем в блоки по первому значению
            3. Упаковываем наиболее оптимальным способом

            ```python
            [2, 8, 9, 10, 12, 35, 62]
            [(0, 2), (0, 8), (0, 9), (0, 10), (0, 12), (2, 3), (3, 14)]
            [(0, 0b0001_0111_0000_0100), (), (2, [3]), (3, [14])]
            ```
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Finite State Transducer

            * Нахождение по ключу за O(1), зависит только от длинны ключа
            * Поиск ключей по префиксу
            * Отличное сжатие для естественных языков
          </section>
          <section data-markdown>
            ## Finite State Transducer

            ```
            0: mop    3: star
            1: moth   4: stop
            2: pop    5: top
            ```

            ![FST](images/numericFST.png)
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Numeric Fields
          </section>
          <section data-markdown>
            ### Ancient times

            * У нас же есть FST
            * Числа тоже строки!
            * Let's sort them: 10, 12, 2, 35, 8
            * Let's fix that: 002, 008, 010, 012, 035
            * Lucene это сделает за вас
          </section>
          <section data-markdown>
            ### Industrial revolution

            * Префиксное дерево - Trie
            * Каждый узел хранит ссылку на Postings List

            ![Trie](images/trie.png)

            ```txt
            423 &lt;= price &lt;= 642

            5 | 44 | 63 | 423 | 641 | 642
            ```
            </pre>
          </section>
          <section data-markdown>
            ## New wave

            * BKD Tree
            * Единая структура для чисел, точек в многомерном пространстве, IPv6 адресов
            * Binary tree & B+ tree
          </section>
          <section data-markdown>
            ## BKD Tree

            ![BKD Tree](images/bkd_tree.png)
          </section>
          <section data-markdown>
            ## BKD Tree

            Неэфективен для больших выборок точечных выборок
		  
            Если не нужен `range` лучше просто хранить числа в строках:
            https://issues.apache.org/jira/browse/SOLR-11078
		  
	    Solr query performance degradation since Solr 6.4.2
		  
	    * Status: Resolved
            * Resolution: Won't fix
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Codecs

            Кодеки в Lucene - это плагины

            ```groovy
            def writerConfig = new IndexWriterConfig(
                new StandardAnalyzer())
            writerConfig.setUseCompoundFile(false)
            writerConfig.setCodec(new SimpleTextCodec())
            def writer = new IndexWriter(dir, writerConfig)
            def doc = new Document()
            doc.add(new StringField('id', '1', Field.Store.YES))
            doc.add(new IntField('status', 1, Field.Store.NO))
            doc.add(new NumericDocValuesField('status', 1))
            doc.add(new TextField(
                'name', 'the brown fox', Field.Store.NO))
            writer.addDocument(doc)
            // add another documents ...
            writer.close()
            ```
          </section>
          <section data-markdown>
            ## Codecs

            ```bash
            $ cat data/_0.pst
            ...
            field name
              term brown
                doc 0
                  freq 1
                  pos 1
                doc 1
                  freq 1
                  pos 1
              term fox
                doc 0
                  freq 1
                  pos 0
            ```
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Segments

            * Немутабельныe
            * Документ нельзя удалить
            * Merges
            * Compound segments для уменьшения кол-ва открытых файлов
          </section>
          <section data-markdown>
            ## Live Docs

            * Единственная мутабельная часть сегмента
            * Внутри Bitmap с пропусками
          </section>
          <section data-markdown>
            <script type="text/template">
              ## Merging Segments

              <iframe width="560" height="315"
                      src="https://www.youtube.com/embed/YOklKW9LJNY"
                      frameborder="0" allowfullscreen></iframe>
            </script>
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Vector Space Model

            ![Vector](images/vector_query.png)
          </section>
          <section data-markdown>
            ## Ranking &amp; Similarity

            Для каждого терма:

            * `TF` - частота терма в документе
            * `tf(t in d) = sqrt(frequency)`
            * `IDF` - инвертированная частота терма в корпусе
            * `idf(t) = 1 + log(numDocs/(docFreq+1))`
            * `norm = 1 / sqrt(numTerms)`
            * `score ~ tf * idf^2 * norm`

            `BM25` - тонкая настройка
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Text processing

            * Фильтрация символов (например удаление html)
            * Разбиение на токены
            * Морфология (стемминг)
            * Синонимы
            * Разделение/объединение (wi fi = wifi = WiFi = wi-fi)
            * Машинное обучение
          </section>
          <section data-markdown>
            ## Stemming

            * Snowball - алгоритмический стеммер
            * Hunspell - медленно
            * Словарь - быстро и точно (используем словари из pymorphy2)
          </section>
        </section>

        <section>
          <section data-markdown>
            ## Elasticsearch
          </section>
          <section data-markdown>
            ### Distributed Search

            ![Distributed Search](images/distributed_query.png)
          </section>
          <section data-markdown>
            ### Distributed Search

            Эй кластер, 10 документов для 2-й страницы:

            1. Сервер на который пришел запрос. Эй шарды, 20 документов мне от каждого:
               * Получают список документов
               * *heapq.nlargest(20)*

            2. Так, 100 хитов от 5 шардов:
               * *kmerge*! *slice[10:20]*!
               * Шарды, а ну документы для этих 10
          </section>
          <section data-markdown>
            <script type="text/template">
            ### Distributed Search

            `IDF` отличается на разных шардах

            <ol start="0">
              <li>
                Получаем из каждого шарда `numDocs` и `docFreq`,
                вычисляем глобальный `IDF` и используем его для
                выполнения запроса
              </li>
            </script>
          </section>
          <section data-markdown>
            ### Query execution phases

            1. Фильтрация
            2. Ранжирование
            2. Агрегации
            3. Пост-фильтрация `post_filter`
          </section>
          <section data-markdown>
            ### Aggregations

            * **Bucket** - набор документов, могут быть вложенными,
              бакет имеет одну метрику: `doc_count`.

              `terms` &amp; `significant_terms`, `filter` &amp; `filters`,
              `histogram`, `range`, `adjacency_matric`,
              `sampler` &amp; `diversified_sampler`
            * **Metric**: `min`, `max`, `sum`, `avg`, `value_count`, `cardinality`,
              `percentiles` &amp; `percentile_ranks`, `top_hits`
          </section>
          <section data-markdown>
            ### Meta fields

            * `_index` - виртуальное поле
            * `_id` - тип и идентификатор документа
            * `_source` - json документа, `stored` поле
            * `_all` - все-в-одном
            * `_field_names` - список названий полей (`exists` query)
            * `_routing` - определяет шард в который попадет документ
            * `_version` - для Optimistic Concurrency Control
          </section>
          <section data-markdown>
            ### Dynamic &amp; Schemaless?

            **string** - Either a date field (if the value passes date detection),
            a double or long field (if the value passes numeric detection) or
            a text field, with a keyword sub-field.

            * Отключаем автоматическое создание индексов:
            ```bash
            $ echo 'action.auto_create_index: false' \
            >> elasticsearch.yml
            ```

            * Отключаем динамическую схему:
            ```bash
            $ curl -XPOST 'localhost:9200/test' -d '---
            settings.index.mapper.dynamic: false'
            ```
          </section>
        </section>

        <section data-markdown>
          https://anti-social.github.io/effective_search_slides
        </section>
      </div>
    </div>

    <script src="reveal.js/lib/js/head.min.js"></script>
    <script src="reveal.js/js/reveal.js"></script>
    <script>
      // Full list of configuration options available at:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        transition: 'slide', // none/fade/slide/convex/concave/zoom
        // Optional reveal.js plugins
        dependencies: [
          {
            src: 'reveal.js/lib/js/classList.js',
            condition: function() { return !document.body.classList; }
          },
          {
            src: 'reveal.js/plugin/markdown/marked.js',
            condition: function() { return !!document.querySelector( '[data-markdown]' ); }
          },
          {
            src: 'reveal.js/plugin/markdown/markdown.js',
            condition: function() { return !!document.querySelector( '[data-markdown]' ); }
          },
          {
            src: 'reveal.js/plugin/highlight/highlight.js',
            async: true,
            callback: function() { hljs.initHighlightingOnLoad(); }
          },
          {
            src: 'reveal.js/plugin/zoom-js/zoom.js',
            async: true
          },
          {
            src: 'reveal.js/plugin/notes/notes.js',
            async: true
          }
        ]
      });
    </script>
  </body>
</html>
